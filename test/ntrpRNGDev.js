/**
 * ntrpRNGDev.js - Development & Testing Suite for ntrpRNG
 * 
 * Provides comprehensive statistical analysis and stress testing tools
 * for validating the quality of seeds generated by ntrpRNG.js and cgRNDV.js.
 * 
 * @version 1.4.0
 * @license MIT
 * @requires ntrpRNG.js or cgRNDV.js
 * 
 * CHANGELOG:
 *
 * v1.4.0 - Added three new statistical tests:
 *        - Chi-Square Test (byte frequency distribution)
 *        - Serial Correlation Test (bit sequence independence)
 *        - Avalanche Effect Test (bit-flip propagation)
 *        - Integrated new tests into runTestSuite() with level-based parameters
 *        - Added concatenated mode support for Chi-Square and Serial Correlation
 * v1.3.0 - Added universal support for both ntrpRNG and cgRNDV
 *        - Auto-detection of RNG type (behavioral vs pure crypto)
 *        - Conditional test execution based on RNG capabilities
 *        - monitorEntropyPool() and analyzeTimingJitter() skipped for pure crypto RNGs
 *        - runTestSuite() adapts to RNG type automatically
 * v1.2.1 - Renamed library file from `ntrprng_dev.js` to `ntrpRNGDev.js` for naming consistency.
 *        - Updated main class name from `NtrpRngDev` → `ntrpRNGDev`.
 * v1.2.0 - Extended concatenated mode to all statistical tests
 *        - Monobit and Runs tests now support concatenated analysis
 *        - Unified test mode across Shannon, Monobit, and Runs
 * v1.1.0 - Added concatenated mode to Shannon Entropy test
 *        - runMultiSeedTest() now supports concatenated parameter
 *        - Analyzes entropy across multiple seeds as single dataset
 */

class ntrpRNGDev {
  /**
   * Create a new testing suite instance
   * @param {ntrpRNG|cgRNDV} rngInstance - Instance of ntrpRNG or cgRNDV to test
   */
  constructor(rngInstance) {
    if (!rngInstance || typeof rngInstance.generateSeed !== 'function') {
      throw new Error('ntrpRNGDev requires a valid RNG instance (ntrpRNG or cgRNDV)');
    }
    this.rng = rngInstance;
    this.testResults = [];
    
    // Detect RNG type
    this.rngType = this._detectRNGType();
    console.log(`Detected RNG type: ${this.rngType}`);
  }
  
  /**
   * Detect RNG type based on available properties
   * @private
   * @returns {string} RNG type: 'behavioral' or 'pure-crypto'
   */
  _detectRNGType() {
    // Check if RNG has behavioral entropy collection capabilities
    const hasBehavioralEntropy = 
      Array.isArray(this.rng.entropyPool) && 
      Array.isArray(this.rng.timerDeltas) &&
      typeof this.rng.eventCount === 'object';
    
    // Check if entropy pools are actually being used
    const stats = this.rng.getStats();
    const hasActiveCollection = 
      stats.entropyPoolSize > 0 || 
      stats.timerDeltasSize > 0 ||
      this.rng.isCollecting === true;
    
    if (hasBehavioralEntropy) {
      return 'behavioral';
    }
    
    return 'pure-crypto';
  }
  
  /**
   * Check if RNG supports behavioral entropy tests
   * @returns {boolean}
   */
  supportsBehavioralTests() {
    return this.rngType === 'behavioral';
  }
  
  /**
   * Calculate Shannon Entropy for byte array
   * H(X) = -Σ(p(x) * log2(p(x)))
   * @private
   * @param {Uint8Array} data - Byte array
   * @returns {number} Shannon entropy in bits per byte (0-8)
   */
  _calculateShannonEntropy(data) {
    const frequency = new Array(256).fill(0);
    
    // Count byte frequencies
    for (let i = 0; i < data.length; i++) {
      frequency[data[i]]++;
    }
    
    // Calculate entropy
    let entropy = 0;
    const len = data.length;
    
    for (let i = 0; i < 256; i++) {
      if (frequency[i] > 0) {
        const p = frequency[i] / len;
        entropy -= p * Math.log2(p);
      }
    }
    
    return entropy;
  }
  
  /**
   * Perform Monobit Test (NIST SP 800-22)
   * Tests if number of 1s and 0s are approximately equal
   * @private
   * @param {Uint8Array} data - Byte array
   * @returns {number} Test statistic (closer to 0 is better)
   */
  _monobitTest(data) {
    let onesCount = 0;
    let totalBits = data.length * 8;
    
    for (let i = 0; i < data.length; i++) {
      let byte = data[i];
      for (let j = 0; j < 8; j++) {
        onesCount += (byte >> j) & 1;
      }
    }
    
    const zerosCount = totalBits - onesCount;
    const sum = onesCount - zerosCount;
    const statistic = Math.abs(sum) / Math.sqrt(totalBits);
    
    return statistic;
  }
  
  /**
   * Perform Runs Test (NIST SP 800-22)
   * Tests for oscillation between consecutive bits
   * @private
   * @param {Uint8Array} data - Byte array
   * @returns {number} Test statistic (lower is better, < 2 is good)
   */
  _runsTest(data) {
    let bits = [];
    
    // Extract all bits
    for (let i = 0; i < data.length; i++) {
      let byte = data[i];
      for (let j = 0; j < 8; j++) {
        bits.push((byte >> j) & 1);
      }
    }
    
    const n = bits.length;
    let onesCount = bits.reduce((a, b) => a + b, 0);
    let pi = onesCount / n;
    
    // Count runs
    let runs = 1;
    for (let i = 1; i < n; i++) {
      if (bits[i] !== bits[i - 1]) {
        runs++;
      }
    }
    
    // Calculate expected runs and variance
    const expectedRuns = 2 * n * pi * (1 - pi) + 1;
    const variance = 2 * n * pi * (1 - pi) * (2 * n * pi * (1 - pi) - 1) / (n - 1);
    
    if (variance === 0) return 0;
    
    const statistic = Math.abs(runs - expectedRuns) / Math.sqrt(variance);
    return statistic;
  }
  
  /**
   * Perform Chi-Square Test
   * Tests uniformity of byte distribution
   * @private
   * @param {Uint8Array} data - Byte array
   * @returns {number} Chi-square statistic (lower is better, < 293.25 for 95% confidence)
   */
  _chiSquareTest(data) {
    const frequency = new Array(256).fill(0);
    
    // Count byte frequencies
    for (let i = 0; i < data.length; i++) {
      frequency[data[i]]++;
    }
    
    // Expected frequency for uniform distribution
    const expected = data.length / 256;
    
    // Calculate chi-square statistic
    let chiSquare = 0;
    for (let i = 0; i < 256; i++) {
      const diff = frequency[i] - expected;
      chiSquare += (diff * diff) / expected;
    }
    
    return chiSquare;
  }
  
  /**
   * Perform Serial Correlation Test
   * Tests independence between consecutive bits
   * @private
   * @param {Uint8Array} data - Byte array
   * @returns {number} Correlation coefficient (closer to 0 is better)
   */
  _serialCorrelationTest(data) {
    let bits = [];
    
    // Extract all bits
    for (let i = 0; i < data.length; i++) {
      let byte = data[i];
      for (let j = 0; j < 8; j++) {
        bits.push((byte >> j) & 1);
      }
    }
    
    const n = bits.length;
    if (n < 2) return 0;
    
    // Calculate mean
    const mean = bits.reduce((a, b) => a + b, 0) / n;
    
    // Calculate autocorrelation at lag 1
    let sumXY = 0;
    let sumX2 = 0;
    
    for (let i = 0; i < n - 1; i++) {
      const x = bits[i] - mean;
      const y = bits[i + 1] - mean;
      sumXY += x * y;
      sumX2 += x * x;
    }
    
    if (sumX2 === 0) return 0;
    
    const correlation = sumXY / sumX2;
    return Math.abs(correlation);
  }
  
  /**
   * Calculate standard deviation
   * @private
   * @param {Array<number>} values - Array of numbers
   * @returns {number} Standard deviation
   */
  _calculateStdDev(values) {
    const mean = values.reduce((a, b) => a + b, 0) / values.length;
    const variance = values.reduce((a, b) => a + Math.pow(b - mean, 2), 0) / values.length;
    return Math.sqrt(variance);
  }
  
  /**
   * Test 1: Generate multiple seeds and analyze statistical quality
   * 
   * Test Levels:
   * - LOW: 10 seeds, 32 bytes each
   * - MEDIUM: 50 seeds, 64 bytes each
   * - HIGH: 100 seeds, 64 bytes each
   * - EXTREME: 500 seeds, 128 bytes each
   * 
   * @param {number} count - Number of seeds to generate
   * @param {number} seedSize - Size of each seed (default: 64 bytes)
   * @param {boolean} concatenated - Calculate all tests on concatenated dataset (default: false)
   * @returns {Promise<Object>} Test results with statistics
   */
  async runMultiSeedTest(count = 10, seedSize = 64, concatenated = false) {
    console.log(`\n=== Multi-Seed Test ===`);
    console.log(`RNG Type: ${this.rngType}`);
    console.log(`Generating ${count} seeds of ${seedSize} bytes each...`);
    console.log(`Test mode: ${concatenated ? 'CONCATENATED' : 'INDIVIDUAL'}`);
    
    const shannonScores = [];
    const monobitScores = [];
    const runsScores = [];
    const chiSquareScores = [];
    const serialCorrScores = [];
    const seeds = [];
    
    const startTime = performance.now();
    
    for (let i = 0; i < count; i++) {
      try {
        const seed = await this.rng.generateSeed(true);
        
        // Use only requested size
        const truncatedSeed = seed.slice(0, seedSize);
        seeds.push(truncatedSeed);
        
        // Calculate metrics for individual seeds (unless concatenated mode)
        if (!concatenated) {
          const shannon = this._calculateShannonEntropy(truncatedSeed);
          const monobit = this._monobitTest(truncatedSeed);
          const runs = this._runsTest(truncatedSeed);
          const chiSquare = this._chiSquareTest(truncatedSeed);
          const serialCorr = this._serialCorrelationTest(truncatedSeed);
          
          shannonScores.push(shannon);
          monobitScores.push(monobit);
          runsScores.push(runs);
          chiSquareScores.push(chiSquare);
          serialCorrScores.push(serialCorr);
        }
        
        if ((i + 1) % Math.max(1, Math.floor(count / 10)) === 0) {
          console.log(`Progress: ${i + 1}/${count} seeds generated`);
        }
      } catch (error) {
        console.error(`Error generating seed ${i + 1}:`, error.message);
      }
    }
    
    // Calculate concatenated tests if requested
    if (concatenated && seeds.length > 0) {
      const totalSize = seeds.reduce((sum, seed) => sum + seed.length, 0);
      const concatenatedData = new Uint8Array(totalSize);
      
      let offset = 0;
      for (let seed of seeds) {
        concatenatedData.set(seed, offset);
        offset += seed.length;
      }
      
      console.log(`Concatenated dataset size: ${totalSize} bytes`);
      console.log(`Running tests on concatenated dataset...`);
      
      const shannonConcatenated = this._calculateShannonEntropy(concatenatedData);
      const monobitConcatenated = this._monobitTest(concatenatedData);
      const runsConcatenated = this._runsTest(concatenatedData);
      const chiSquareConcatenated = this._chiSquareTest(concatenatedData);
      const serialCorrConcatenated = this._serialCorrelationTest(concatenatedData);
      
      shannonScores.push(shannonConcatenated);
      monobitScores.push(monobitConcatenated);
      runsScores.push(runsConcatenated);
      chiSquareScores.push(chiSquareConcatenated);
      serialCorrScores.push(serialCorrConcatenated);
    }
    
    const endTime = performance.now();
    const duration = (endTime - startTime) / 1000;
    
    // Calculate statistics
    const results = {
      rngType: this.rngType,
      count: seeds.length,
      seedSize: seedSize,
      duration: duration.toFixed(2) + 's',
      concatenatedMode: concatenated,
      shannonEntropy: concatenated ? {
        value: shannonScores[0].toFixed(4),
        datasetSize: seeds.length * seedSize + ' bytes',
        ideal: '7.9-8.0 bits/byte'
      } : {
        mean: (shannonScores.reduce((a, b) => a + b, 0) / shannonScores.length).toFixed(4),
        stdDev: this._calculateStdDev(shannonScores).toFixed(4),
        min: Math.min(...shannonScores).toFixed(4),
        max: Math.max(...shannonScores).toFixed(4),
        ideal: '7.9-8.0 bits/byte'
      },
      monobitTest: concatenated ? {
        value: monobitScores[0].toFixed(4),
        datasetSize: seeds.length * seedSize + ' bytes',
        ideal: '< 2.0 (closer to 0)'
      } : {
        mean: (monobitScores.reduce((a, b) => a + b, 0) / monobitScores.length).toFixed(4),
        stdDev: this._calculateStdDev(monobitScores).toFixed(4),
        min: Math.min(...monobitScores).toFixed(4),
        max: Math.max(...monobitScores).toFixed(4),
        ideal: '< 2.0 (closer to 0)'
      },
      runsTest: concatenated ? {
        value: runsScores[0].toFixed(4),
        datasetSize: seeds.length * seedSize + ' bytes',
        ideal: '< 2.0 (lower is better)'
      } : {
        mean: (runsScores.reduce((a, b) => a + b, 0) / runsScores.length).toFixed(4),
        stdDev: this._calculateStdDev(runsScores).toFixed(4),
        min: Math.min(...runsScores).toFixed(4),
        max: Math.max(...runsScores).toFixed(4),
        ideal: '< 2.0 (lower is better)'
      },
      chiSquareTest: concatenated ? {
        value: chiSquareScores[0].toFixed(4),
        datasetSize: seeds.length * seedSize + ' bytes',
        ideal: '< 293.25 (95% confidence)'
      } : {
        mean: (chiSquareScores.reduce((a, b) => a + b, 0) / chiSquareScores.length).toFixed(4),
        stdDev: this._calculateStdDev(chiSquareScores).toFixed(4),
        min: Math.min(...chiSquareScores).toFixed(4),
        max: Math.max(...chiSquareScores).toFixed(4),
        ideal: '< 293.25 (95% confidence)'
      },
      serialCorrelationTest: concatenated ? {
        value: serialCorrScores[0].toFixed(4),
        datasetSize: seeds.length * seedSize + ' bytes',
        ideal: '< 0.1 (closer to 0)'
      } : {
        mean: (serialCorrScores.reduce((a, b) => a + b, 0) / serialCorrScores.length).toFixed(4),
        stdDev: this._calculateStdDev(serialCorrScores).toFixed(4),
        min: Math.min(...serialCorrScores).toFixed(4),
        max: Math.max(...serialCorrScores).toFixed(4),
        ideal: '< 0.1 (closer to 0)'
      }
    };
    
    console.log('\nResults:');
    console.log(`Seeds Generated: ${results.count}`);
    console.log(`Duration: ${results.duration}`);
    
    if (concatenated) {
      console.log(`\nShannon Entropy (Concatenated): ${results.shannonEntropy.value} (${results.shannonEntropy.ideal})`);
      console.log(`  Dataset: ${results.shannonEntropy.datasetSize}`);
      console.log(`\nMonobit Test (Concatenated): ${results.monobitTest.value} (${results.monobitTest.ideal})`);
      console.log(`  Dataset: ${results.monobitTest.datasetSize}`);
      console.log(`\nRuns Test (Concatenated): ${results.runsTest.value} (${results.runsTest.ideal})`);
      console.log(`  Dataset: ${results.runsTest.datasetSize}`);
      console.log(`\nChi-Square Test (Concatenated): ${results.chiSquareTest.value} (${results.chiSquareTest.ideal})`);
      console.log(`  Dataset: ${results.chiSquareTest.datasetSize}`);
      console.log(`\nSerial Correlation (Concatenated): ${results.serialCorrelationTest.value} (${results.serialCorrelationTest.ideal})`);
      console.log(`  Dataset: ${results.serialCorrelationTest.datasetSize}`);
    } else {
      console.log(`\nShannon Entropy (Individual): ${results.shannonEntropy.mean} ± ${results.shannonEntropy.stdDev} (${results.shannonEntropy.ideal})`);
      console.log(`  Range: [${results.shannonEntropy.min}, ${results.shannonEntropy.max}]`);
      console.log(`\nMonobit Test (Individual): ${results.monobitTest.mean} ± ${results.monobitTest.stdDev} (${results.monobitTest.ideal})`);
      console.log(`  Range: [${results.monobitTest.min}, ${results.monobitTest.max}]`);
      console.log(`\nRuns Test (Individual): ${results.runsTest.mean} ± ${results.runsTest.stdDev} (${results.runsTest.ideal})`);
      console.log(`  Range: [${results.runsTest.min}, ${results.runsTest.max}]`);
      console.log(`\nChi-Square Test (Individual): ${results.chiSquareTest.mean} ± ${results.chiSquareTest.stdDev} (${results.chiSquareTest.ideal})`);
      console.log(`  Range: [${results.chiSquareTest.min}, ${results.chiSquareTest.max}]`);
      console.log(`\nSerial Correlation (Individual): ${results.serialCorrelationTest.mean} ± ${results.serialCorrelationTest.stdDev} (${results.serialCorrelationTest.ideal})`);
      console.log(`  Range: [${results.serialCorrelationTest.min}, ${results.serialCorrelationTest.max}]`);
    }
    
    this.testResults.push({ test: 'MultiSeed', timestamp: Date.now(), results });
    return results;
  }
  
  /**
   * Test 2: Monitor entropy pool statistics over time
   * ONLY AVAILABLE FOR BEHAVIORAL RNGs (ntrpRNG)
   * 
   * Test Levels:
   * - LOW: 100ms interval, 30 samples
   * - MEDIUM: 50ms interval, 60 samples
   * - HIGH: 20ms interval, 100 samples
   * - EXTREME: 10ms interval, 300 samples
   * 
   * @param {number} intervalMs - Sampling interval in milliseconds
   * @param {number} maxSamples - Maximum number of samples (default: 30)
   * @returns {Promise<void>}
   */
  async monitorEntropyPool(intervalMs = 100, maxSamples = 30) {
    if (!this.supportsBehavioralTests()) {
      console.log(`\n=== Entropy Pool Monitor ===`);
      console.log(`SKIPPED: ${this.rngType} RNG does not collect behavioral entropy`);
      return;
    }
    
    console.log(`\n=== Entropy Pool Monitor ===`);
    console.log(`Sampling every ${intervalMs}ms for ${maxSamples} samples...`);
    
    const samples = [];
    let sampleCount = 0;
    
    return new Promise((resolve) => {
      const intervalId = setInterval(() => {
        const stats = this.rng.getStats();
        const sample = {
          timestamp: Date.now(),
          poolSize: stats.entropyPoolSize,
          timerSize: stats.timerDeltasSize,
          totalEvents: stats.totalEvents
        };
        
        samples.push(sample);
        
        // Calculate variance if we have enough samples
        if (samples.length > 1) {
          const poolSizes = samples.map(s => s.poolSize);
          const poolVariance = this._calculateStdDev(poolSizes);
          
          console.log(
            `Sample ${samples.length}/${maxSamples}: ` +
            `Pool=${sample.poolSize}, Timer=${sample.timerSize}, ` +
            `Events=${sample.totalEvents}, Variance=${poolVariance.toFixed(2)}`
          );
        } else {
          console.log(
            `Sample ${samples.length}/${maxSamples}: ` +
            `Pool=${sample.poolSize}, Timer=${sample.timerSize}, ` +
            `Events=${sample.totalEvents}`
          );
        }
        
        sampleCount++;
        
        if (sampleCount >= maxSamples) {
          clearInterval(intervalId);
          
          // Final statistics
          const poolSizes = samples.map(s => s.poolSize);
          const timerSizes = samples.map(s => s.timerSize);
          
          console.log('\nFinal Statistics:');
          console.log(`Pool Size - Mean: ${(poolSizes.reduce((a,b)=>a+b,0)/poolSizes.length).toFixed(2)}, ` +
                      `StdDev: ${this._calculateStdDev(poolSizes).toFixed(2)}`);
          console.log(`Timer Size - Mean: ${(timerSizes.reduce((a,b)=>a+b,0)/timerSizes.length).toFixed(2)}, ` +
                      `StdDev: ${this._calculateStdDev(timerSizes).toFixed(2)}`);
          
          resolve();
        }
      }, intervalMs);
    });
  }
  
  /**
   * Test 3: Verify salt generation consistency and uniqueness
   * 
   * Test Levels:
   * - LOW: 100 iterations
   * - MEDIUM: 500 iterations
   * - HIGH: 1000 iterations
   * - EXTREME: 5000 iterations
   * 
   * @param {number} iterations - Number of salts to generate
   * @returns {Promise<Object>} Test results
   */
  async verifySaltConsistency(iterations = 100) {
    console.log(`\n=== Salt Consistency Test ===`);
    console.log(`RNG Type: ${this.rngType}`);
    console.log(`Generating ${iterations} salts...`);
    
    const saltHashes = new Set();
    const saltLengths = [];
    let collisions = 0;
    
    const startTime = performance.now();
    
    for (let i = 0; i < iterations; i++) {
      const salt = this.rng.generateSalt();
      saltLengths.push(salt.length);
      
      // Hash the salt for collision detection
      const saltBuffer = await crypto.subtle.digest('SHA-256', salt);
      const saltHash = this.rng.toHex(new Uint8Array(saltBuffer));
      
      if (saltHashes.has(saltHash)) {
        collisions++;
        console.warn(`Collision detected at iteration ${i + 1}`);
      }
      
      saltHashes.add(saltHash);
      
      if ((i + 1) % Math.max(1, Math.floor(iterations / 10)) === 0) {
        console.log(`Progress: ${i + 1}/${iterations} salts generated`);
      }
    }
    
    const endTime = performance.now();
    const duration = (endTime - startTime) / 1000;
    
    const uniqueCount = saltHashes.size;
    const collisionRate = (collisions / iterations * 100).toFixed(4);
    const avgLength = (saltLengths.reduce((a, b) => a + b, 0) / saltLengths.length).toFixed(2);
    
    const results = {
      rngType: this.rngType,
      iterations,
      uniqueSalts: uniqueCount,
      collisions,
      collisionRate: collisionRate + '%',
      averageLength: avgLength + ' bytes',
      duration: duration.toFixed(2) + 's',
      passed: collisions === 0
    };
    
    console.log('\nResults:');
    console.log(`Total Salts: ${iterations}`);
    console.log(`Unique Salts: ${uniqueCount}`);
    console.log(`Collisions: ${collisions} (${collisionRate}%)`);
    console.log(`Average Length: ${avgLength} bytes`);
    console.log(`Duration: ${results.duration}`);
    console.log(`Test Status: ${results.passed ? 'PASSED ✓' : 'FAILED ✗'}`);
    
    this.testResults.push({ test: 'SaltConsistency', timestamp: Date.now(), results });
    return results;
  }
  
  /**
   * Test 4: Analyze timing jitter distribution
   * ONLY AVAILABLE FOR BEHAVIORAL RNGs (ntrpRNG)
   * 
   * Test Levels:
   * - LOW: 100 samples
   * - MEDIUM: 500 samples
   * - HIGH: 1000 samples
   * - EXTREME: 5000 samples
   * 
   * @param {number} samples - Number of samples to collect
   * @returns {Promise<Object>} Statistical analysis of timing jitter
   */
  async analyzeTimingJitter(samples = 100) {
    if (!this.supportsBehavioralTests()) {
      console.log(`\n=== Timing Jitter Analysis ===`);
      console.log(`SKIPPED: ${this.rngType} RNG does not collect timing jitter`);
      return { skipped: true, reason: 'Not supported by ' + this.rngType };
    }
    
    console.log(`\n=== Timing Jitter Analysis ===`);
    console.log(`Collecting ${samples} timing samples...`);
    
    // Ensure collection is active
    const wasCollecting = this.rng.isCollecting;
    if (!wasCollecting) {
      this.rng.startCollecting();
    }
    
    // Wait for collection
    await new Promise(resolve => setTimeout(resolve, 100));
    
    const initialStats = this.rng.getStats();
    
    // Wait to collect more samples
    const waitTime = Math.min(samples * 2, 3000);
    await new Promise(resolve => setTimeout(resolve, waitTime));
    
    const finalStats = this.rng.getStats();
    
    // Access timer deltas (note: this is private, for testing only)
    const timerDeltas = this.rng.timerDeltas || [];
    const recentDeltas = timerDeltas.slice(-Math.min(samples, timerDeltas.length));
    
    if (recentDeltas.length === 0) {
      console.warn('No timer deltas collected. Ensure RNG is collecting.');
      return { error: 'No data collected' };
    }
    
    // Calculate statistics
    const min = Math.min(...recentDeltas);
    const max = Math.max(...recentDeltas);
    const mean = recentDeltas.reduce((a, b) => a + b, 0) / recentDeltas.length;
    const stdDev = this._calculateStdDev(recentDeltas);
    
    // Create histogram (10 bins)
    const binCount = 10;
    const binSize = (max - min) / binCount;
    const histogram = new Array(binCount).fill(0);
    
    for (let delta of recentDeltas) {
      const binIndex = Math.min(Math.floor((delta - min) / binSize), binCount - 1);
      histogram[binIndex]++;
    }
    
    const results = {
      rngType: this.rngType,
      samplesAnalyzed: recentDeltas.length,
      min: min.toFixed(4),
      max: max.toFixed(4),
      mean: mean.toFixed(4),
      stdDev: stdDev.toFixed(4),
      range: (max - min).toFixed(4),
      coefficientOfVariation: ((stdDev / mean) * 100).toFixed(2) + '%',
      histogram: histogram
    };
    
    console.log('\nResults:');
    console.log(`Samples Analyzed: ${results.samplesAnalyzed}`);
    console.log(`Min: ${results.min}ms`);
    console.log(`Max: ${results.max}ms`);
    console.log(`Mean: ${results.mean}ms`);
    console.log(`StdDev: ${results.stdDev}ms`);
    console.log(`Range: ${results.range}ms`);
    console.log(`Coefficient of Variation: ${results.coefficientOfVariation}`);
    console.log('\nHistogram:');
    histogram.forEach((count, i) => {
      const binStart = (min + i * binSize).toFixed(2);
      const binEnd = (min + (i + 1) * binSize).toFixed(2);
      const bar = '█'.repeat(Math.ceil(count / Math.max(...histogram) * 40));
      console.log(`[${binStart}-${binEnd}]: ${bar} (${count})`);
    });
    
    // Restore collection state
    if (!wasCollecting) {
      this.rng.stopCollecting();
    }
    
    this.testResults.push({ test: 'TimingJitter', timestamp: Date.now(), results });
    return results;
  }
  
  /**
   * Test 5: Check seed repeatability (seeds should NOT repeat)
   * 
   * Test Levels:
   * - LOW: 2 seeds
   * - MEDIUM: 5 seeds
   * - HIGH: 10 seeds
   * - EXTREME: 20 seeds
   * 
   * @param {number} iterations - Number of seed pairs to test (default: 2)
   * @returns {Promise<Object>} Test results
   */
  async checkRepeatability(iterations = 2) {
    console.log(`\n=== Repeatability Check ===`);
    console.log(`RNG Type: ${this.rngType}`);
    console.log(`Testing ${iterations} seed generations for uniqueness...`);
    
    const seeds = [];
    const seedHashes = new Set();
    let repeats = 0;
    
    const startTime = performance.now();
    
    for (let i = 0; i < iterations; i++) {
      // Generate seed
      const seed = await this.rng.generateSeed(true);
      
      // Hash for comparison
      const seedBuffer = await crypto.subtle.digest('SHA-256', seed);
      const seedHash = this.rng.toHex(new Uint8Array(seedBuffer));
      
      if (seedHashes.has(seedHash)) {
        repeats++;
        console.warn(`REPEAT DETECTED at iteration ${i + 1}!`);
        console.warn(`Seed hash: ${seedHash.substring(0, 32)}...`);
      }
      
      seeds.push(seed);
      seedHashes.add(seedHash);
      
      console.log(`Seed ${i + 1}: ${this.rng.toHex(seed).substring(0, 32)}...`);
      
      // Small delay between generations
      await new Promise(resolve => setTimeout(resolve, 50));
    }
    
    const endTime = performance.now();
    const duration = (endTime - startTime) / 1000;
    
    // Calculate Hamming distances between consecutive seeds
    const hammingDistances = [];
    for (let i = 1; i < seeds.length; i++) {
      let distance = 0;
      for (let j = 0; j < Math.min(seeds[i-1].length, seeds[i].length); j++) {
        const xor = seeds[i-1][j] ^ seeds[i][j];
        distance += xor.toString(2).split('1').length - 1;
      }
      hammingDistances.push(distance);
    }
    
    const avgHammingDistance = hammingDistances.length > 0
      ? (hammingDistances.reduce((a, b) => a + b, 0) / hammingDistances.length).toFixed(2)
      : 'N/A';
    
    const results = {
      rngType: this.rngType,
      iterations,
      uniqueSeeds: seedHashes.size,
      repeats,
      repeatRate: ((repeats / iterations) * 100).toFixed(2) + '%',
      averageHammingDistance: avgHammingDistance + ' bits',
      duration: duration.toFixed(2) + 's',
      passed: repeats === 0
    };
    
    console.log('\nResults:');
    console.log(`Total Seeds: ${iterations}`);
    console.log(`Unique Seeds: ${results.uniqueSeeds}`);
    console.log(`Repeats: ${repeats}`);
    console.log(`Repeat Rate: ${results.repeatRate}`);
    console.log(`Avg Hamming Distance: ${avgHammingDistance} bits`);
    console.log(`Duration: ${results.duration}`);
    console.log(`Test Status: ${results.passed ? 'PASSED ✓' : 'FAILED ✗'}`);
    
    this.testResults.push({ test: 'Repeatability', timestamp: Date.now(), results });
    return results;
  }
  
  /**
   * Test 6: Avalanche Effect Analysis
   * Tests bit-flip propagation (changing one bit should affect ~50% of output bits)
   * 
   * Test Levels:
   * - LOW: 10 seed pairs
   * - MEDIUM: 25 seed pairs
   * - HIGH: 50 seed pairs
   * - EXTREME: 100 seed pairs
   * 
   * @param {number} iterations - Number of seed pairs to analyze (default: 10)
   * @returns {Promise<Object>} Avalanche effect statistics
   */
  async testAvalancheEffect(iterations = 10) {
    console.log(`\n=== Avalanche Effect Test ===`);
    console.log(`RNG Type: ${this.rngType}`);
    console.log(`Analyzing ${iterations} seed pairs for bit-flip propagation...`);
    
    const avalancheScores = [];
    
    const startTime = performance.now();
    
    for (let i = 0; i < iterations; i++) {
      // Generate first seed
      const seed1 = await this.rng.generateSeed(true);
      
      // Small delay
      await new Promise(resolve => setTimeout(resolve, 10));
      
      // Generate second seed
      const seed2 = await this.rng.generateSeed(true);
      
      // Calculate Hamming distance
      const minLength = Math.min(seed1.length, seed2.length);
      let flippedBits = 0;
      
      for (let j = 0; j < minLength; j++) {
        const xor = seed1[j] ^ seed2[j];
        // Count set bits in XOR result
        flippedBits += xor.toString(2).split('1').length - 1;
      }
      
      const totalBits = minLength * 8;
      const avalanchePercentage = (flippedBits / totalBits) * 100;
      avalancheScores.push(avalanchePercentage);
      
      if ((i + 1) % Math.max(1, Math.floor(iterations / 10)) === 0) {
        console.log(`Progress: ${i + 1}/${iterations} pairs analyzed`);
      }
    }
    
    const endTime = performance.now();
    const duration = (endTime - startTime) / 1000;
    
    // Calculate statistics
    const mean = avalancheScores.reduce((a, b) => a + b, 0) / avalancheScores.length;
    const stdDev = this._calculateStdDev(avalancheScores);
    const min = Math.min(...avalancheScores);
    const max = Math.max(...avalancheScores);
    
    // Ideal avalanche is 50% (half the bits flip)
    const deviationFrom50 = Math.abs(mean - 50);
    const passed = deviationFrom50 < 5; // Within 5% of ideal
    
    const results = {
      rngType: this.rngType,
      iterations,
      meanAvalanche: mean.toFixed(4) + '%',
      stdDev: stdDev.toFixed(4) + '%',
      min: min.toFixed(4) + '%',
      max: max.toFixed(4) + '%',
      deviationFrom50: deviationFrom50.toFixed(4) + '%',
      ideal: '50% ± 5%',
      duration: duration.toFixed(2) + 's',
      passed: passed
    };
    
    console.log('\nResults:');
    console.log(`Mean Avalanche: ${results.meanAvalanche} (ideal: ${results.ideal})`);
    console.log(`StdDev: ${results.stdDev}`);
    console.log(`Range: [${results.min}, ${results.max}]`);
    console.log(`Deviation from 50%: ${results.deviationFrom50}`);
    console.log(`Duration: ${results.duration}`);
    console.log(`Test Status: ${results.passed ? 'PASSED ✓' : 'FAILED ✗'}`);
    
    this.testResults.push({ test: 'AvalancheEffect', timestamp: Date.now(), results });
    return results;
  }
  
  /**
   * Run predefined test suite by level
   * Automatically adapts to RNG type (behavioral vs pure-crypto)
   * @param {string} level - Test level: 'low', 'medium', 'high', 'extreme'
   * @returns {Promise<Object>} Combined test results
   */
  async runTestSuite(level = 'medium') {
    const levels = {
      low: {
        multiSeed: { count: 10, size: 32 },
        monitor: { interval: 100, samples: 30 },
        salt: { iterations: 100 },
        jitter: { samples: 100 },
        repeatability: { iterations: 2 },
        avalanche: { iterations: 10 }
      },
      medium: {
        multiSeed: { count: 50, size: 64 },
        monitor: { interval: 50, samples: 60 },
        salt: { iterations: 500 },
        jitter: { samples: 500 },
        repeatability: { iterations: 5 },
        avalanche: { iterations: 25 }
      },
      high: {
        multiSeed: { count: 100, size: 64 },
        monitor: { interval: 20, samples: 100 },
        salt: { iterations: 1000 },
        jitter: { samples: 1000 },
        repeatability: { iterations: 10 },
        avalanche: { iterations: 50 }
      },
      extreme: {
        multiSeed: { count: 500, size: 128 },
        monitor: { interval: 10, samples: 300 },
        salt: { iterations: 5000 },
        jitter: { samples: 5000 },
        repeatability: { iterations: 20 },
        avalanche: { iterations: 100 }
      }
    };
    
    const params = levels[level.toLowerCase()] || levels.medium;
    
    console.log(`\n${'='.repeat(50)}`);
    console.log(`RUNNING TEST SUITE - ${level.toUpperCase()} LEVEL`);
    console.log(`RNG Type: ${this.rngType}`);
    console.log('='.repeat(50));
    
    const suiteStart = Date.now();
    
    const results = {
      level,
      rngType: this.rngType,
      timestamp: suiteStart,
      tests: {}
    };
    
    // Run all tests (some will be skipped based on RNG type)
    results.tests.multiSeed = await this.runMultiSeedTest(
      params.multiSeed.count,
      params.multiSeed.size
    );
    
    // Only run behavioral tests for behavioral RNGs
    if (this.supportsBehavioralTests()) {
      await this.monitorEntropyPool(
        params.monitor.interval,
        params.monitor.samples
      );
      
      results.tests.jitter = await this.analyzeTimingJitter(params.jitter.samples);
    } else {
      console.log(`\nSkipping behavioral tests (monitorEntropyPool, analyzeTimingJitter)`);
      console.log(`Reason: ${this.rngType} RNG does not support behavioral entropy collection\n`);
    }
    
    results.tests.salt = await this.verifySaltConsistency(params.salt.iterations);
    
    results.tests.repeatability = await this.checkRepeatability(
      params.repeatability.iterations
    );
    
    results.tests.avalanche = await this.testAvalancheEffect(
      params.avalanche.iterations
    );
    
    const suiteEnd = Date.now();
    const totalDuration = ((suiteEnd - suiteStart) / 1000).toFixed(2);
    
    console.log(`\n${'='.repeat(50)}`);
    console.log(`TEST SUITE COMPLETE - Duration: ${totalDuration}s`);
    console.log(`RNG Type: ${this.rngType}`);
    console.log('='.repeat(50));
    
    return results;
  }
  
  /**
   * Get all stored test results
   * @returns {Array<Object>} Array of test results
   */
  getTestResults() {
    return this.testResults;
  }
  
  /**
   * Clear all stored test results
   */
  clearTestResults() {
    this.testResults = [];
  }
}

// Export for ES modules
if (typeof module !== 'undefined' && module.exports) {
  module.exports = ntrpRNGDev;
}

// Global export for browser
if (typeof window !== 'undefined') {
  window.ntrpRNGDev = ntrpRNGDev;
}